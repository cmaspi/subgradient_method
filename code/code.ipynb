{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from tqdm.autonotebook import tqdm as notebook_tqdm\n",
    "# importing the data\n",
    "from data import *\n",
    "X = X.T\n",
    "Y = Y.T\n",
    "x_train = np.array([*X[:40],*Y[:40]])\n",
    "x_test = np.array([*X[40:],*Y[40:]])\n",
    "y_train = np.ones(80)\n",
    "y_train[40:] = -np.ones(40)\n",
    "y_test = np.ones(20)\n",
    "y_test[10:] = -np.ones(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random',perplexity=30, n_iter = 1000).fit_transform(x_train)\n",
    "\n",
    "plt.scatter(X_embedded[:40,0],X_embedded[:40,1], label='X')\n",
    "plt.scatter(X_embedded[40:,0],X_embedded[40:,1], label='Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "accuracy = lambda predicted, label: np.mean(predicted==label)\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "accuracy(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.73902605644058\n"
     ]
    }
   ],
   "source": [
    "print(2/np.linalg.norm(clf.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM gives an accuracy of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our own svm trained using subgradient method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = lambda predicted, label: torch.mean((predicted==label).float())\n",
    "\n",
    "import torch\n",
    "class svm:\n",
    "    @classmethod\n",
    "    def __init__(self, trade_off: int = 10):\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.trade_off = torch.tensor(trade_off)\n",
    "        self.learning_rate = None\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def shuffle(train: torch.tensor, labels: torch.tensor):\n",
    "        \"\"\"\n",
    "        Shuffles the data in a random permutation\n",
    "        \"\"\"\n",
    "        n = train.shape[0]\n",
    "        permutation = torch.randperm(n)\n",
    "        train = train[permutation]\n",
    "        labels = labels[permutation]\n",
    "        return train, labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def iterate_minibatches(train : torch.tensor, labels: torch.tensor, batch_size : int):\n",
    "        \"\"\"\n",
    "        Gives minibatches\n",
    "        \"\"\"\n",
    "        for start_idx in range(0, train.shape[0] + 1 - batch_size, batch_size):\n",
    "            excerpt = slice(start_idx, start_idx+batch_size)\n",
    "            yield train[excerpt], labels[excerpt]\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def fit_util(self, train: torch.tensor, labels: torch.tensor):\n",
    "        \"\"\"\n",
    "        Utility function for fit\n",
    "        \"\"\"\n",
    "        \n",
    "        indices = (labels * (train @ self.w + self.b )) < 1.\n",
    "        # n = torch.sqrt(4/(self.w@self.w))\n",
    "        grad_b = -torch.sum(labels[indices])\n",
    "        grad_w = 2 * self.w  - self.trade_off * (labels[indices] @ train[indices])\n",
    "        self.b -=  self.learning_rate * grad_b\n",
    "        self.w -= self.learning_rate * grad_w\n",
    "        if n>100:\n",
    "            print((labels[indices] @ train[indices]))\n",
    "            print(torch.sqrt(4/(self.w@self.w)))\n",
    "\n",
    "    @classmethod\n",
    "    def fit(self, train, labels, learning_rate : int = 0.1 ,epochs : int = 10, batch_size = 10):\n",
    "        \"\"\"\n",
    "        Trains the weights\n",
    "        \"\"\"\n",
    "        self.learning_rate = torch.tensor(learning_rate)\n",
    "        s = train.shape[1]\n",
    "        self.w = torch.normal(torch.zeros(s)).to(torch.float64)\n",
    "        self.b = torch.tensor(0.).to(torch.float64)\n",
    "        \n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.learning_rate = 1/(epoch+1)\n",
    "            train, labels = self.shuffle(train, labels)\n",
    "            for x,y in self.iterate_minibatches(train, labels, batch_size):\n",
    "                self.fit_util(x, y)\n",
    "\n",
    "    @classmethod\n",
    "    def predict(self, test):\n",
    "        \"\"\"\n",
    "        returns the predicted label\n",
    "        \"\"\"\n",
    "        logits = test @ self.w + self.b\n",
    "        return torch.sign(logits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.9572,  1.1508,  1.0628,  0.9374,  1.3040,  1.0761,  0.9887,  1.1928,\n",
      "         1.0451,  1.1355, -0.9625, -0.8612, -1.0348, -1.0082, -1.0248, -1.1893,\n",
      "        -1.0225, -1.0941, -0.9355, -1.1935], dtype=torch.float64)\n",
      "The accuracy of our model is 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train_ = torch.tensor(x_train)\n",
    "x_test_ = torch.tensor(x_test)\n",
    "y_train_ = torch.tensor(y_train)\n",
    "y_test_ = torch.tensor(y_test)\n",
    "\n",
    "clf = svm(0.0003)\n",
    "clf.fit(x_train_, y_train_, epochs = 20, batch_size = 4, learning_rate = 0.1)\n",
    "print(x_test_ @ clf.w + clf.b)\n",
    "y_pred = clf.predict(x_test_)\n",
    "print(\"The accuracy of our model is {}\".format(accuracy(y_pred, y_test_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(128.4273, dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(4/(clf.w@clf.w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with above implementation is that a steady step size can often cause increase in value of the objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible solutions\n",
    "\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = lambda predicted, label: torch.mean((predicted==label).float())\n",
    "\n",
    "import torch\n",
    "class svm:\n",
    "    @classmethod\n",
    "    def __init__(self, trade_off: int = 10):\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.trade_off = torch.tensor(trade_off)\n",
    "        self.learning_rate = None\n",
    "        self.epsilon = 0.001\n",
    "        self.best_w = None\n",
    "        self.best_b = None\n",
    "        self.opt_cost = 1e9\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def shuffle(train: torch.tensor, labels: torch.tensor):\n",
    "        \"\"\"\n",
    "        Shuffles the data in a random permutation\n",
    "        \"\"\"\n",
    "        n = train.shape[0]\n",
    "        permutation = torch.randperm(n)\n",
    "        train = train[permutation]\n",
    "        labels = labels[permutation]\n",
    "        return train, labels\n",
    "    \n",
    "    @staticmethod\n",
    "    def iterate_minibatches(train : torch.tensor, labels: torch.tensor, batch_size : int):\n",
    "        \"\"\"\n",
    "        Gives minibatches\n",
    "        \"\"\"\n",
    "        for start_idx in range(0, train.shape[0] + 1 - batch_size, batch_size):\n",
    "            excerpt = slice(start_idx, start_idx+batch_size)\n",
    "            yield train[excerpt], labels[excerpt]\n",
    "\n",
    "    @classmethod\n",
    "    def cost(self, train, labels):\n",
    "        return self.w @ self.w + np.maximum( 0 , 1 - labels @ (train @ self.w + self.b))\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def fit_util(self, train: torch.tensor, labels: torch.tensor):\n",
    "        \"\"\"\n",
    "        Utility function for fit\n",
    "        \"\"\"\n",
    "        indices = (labels * (train @ self.w + self.b )) < 1.\n",
    "        grad_b = -torch.sum(labels[indices])\n",
    "        grad_w = 2 * self.w  - self.trade_off * (labels[indices] @ train[indices])\n",
    "        self.b -=  self.learning_rate * grad_b\n",
    "        self.w -= self.learning_rate * grad_w / self.trade_off\n",
    "        if self.opt_cost > self.cost(train, labels):\n",
    "            self.best_b = self.b\n",
    "            self.best_w = self.w\n",
    "            self.opt_cost = self.cost(train, labels)\n",
    "    @classmethod\n",
    "    def fit(self, train, labels, learning_rate : int = 0.1 ,epochs : int = 10, batch_size = 10):\n",
    "        \"\"\"\n",
    "        Trains the weights\n",
    "        \"\"\"\n",
    "        self.learning_rate = torch.tensor(learning_rate)\n",
    "        s = train.shape[1]\n",
    "        self.w = torch.normal(torch.zeros(s)).to(torch.float64)\n",
    "        self.b = torch.tensor(0.).to(torch.float64)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            train, labels = self.shuffle(train, labels)\n",
    "            for x,y in self.iterate_minibatches(train, labels, batch_size):\n",
    "                self.fit_util(x, y)\n",
    "        self.w = self.best_w\n",
    "        self.b = self.best_b\n",
    "                \n",
    "\n",
    "    @classmethod\n",
    "    def predict(self, test):\n",
    "        \"\"\"\n",
    "        returns the predicted label\n",
    "        \"\"\"\n",
    "        logits = test @ self.w + self.b\n",
    "        return torch.sign(logits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.2111,  1.4387,  1.2645,  1.2299,  1.5661,  1.2885,  1.3092,  1.4331,\n",
      "         1.3294,  1.4665, -1.2325, -1.0683, -1.3352, -1.2045, -1.3057, -1.4026,\n",
      "        -1.1853, -1.3557, -1.1751, -1.5006], dtype=torch.float64)\n",
      "The accuracy of our model is 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train_ = torch.tensor(x_train)\n",
    "x_test_ = torch.tensor(x_test)\n",
    "y_train_ = torch.tensor(y_train)\n",
    "y_test_ = torch.tensor(y_test)\n",
    "\n",
    "clf = svm(1)\n",
    "clf.epsilon = 1e-5\n",
    "clf.fit(x_train_, y_train_, epochs = 50000, batch_size = 4, learning_rate = 0.00005)\n",
    "print(x_test_ @ clf.w + clf.b)\n",
    "y_pred = clf.predict(x_test_)\n",
    "print(\"The accuracy of our model is {}\".format(accuracy(y_pred, y_test_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(104.3989, dtype=torch.float64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(4/(clf.w@clf.w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
